{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Callable, Union\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def compile(self, weights_sz:int):\n",
    "        self.weights = np.array([random.uniform(0, 10) for _ in range(weights_sz)]).reshape(weights_sz, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def sigmoid(self, x:float)-> float:\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def linearfctn(self, x:float) -> float:\n",
    "        return x\n",
    "    \n",
    "    def softmax(self, x:np.array) -> np.array:\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n",
    "    \n",
    "    def __init__(self, neurons:int, act_fctn:Union[str| Callable]=None, name:str=None):\n",
    "        self.name = name\n",
    "        if act_fctn is None:\n",
    "            self.actn_fn = self.linearfctn\n",
    "        else:\n",
    "            self.actn_fn = self.sigmoid if act_fctn==\"sigmoid\" else self.softmax\n",
    "            \n",
    "        self.neurons = [Neuron() for _ in range(neurons)]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Layer : {self.name}, activation function : {self.actn_fn}, No. of neurons : {len(self.neurons)}\"\n",
    "\n",
    "    def compile(self, childs:int=None):\n",
    "        for i in self.neurons:\n",
    "            i.compile(childs)\n",
    "        self.weights = [neuron.weights for neuron in self.neurons]\n",
    "        return len(self.neurons)\n",
    "    \n",
    "    def forward(self, inp:np.array):\n",
    "        z = inp @ np.array(self.weights).squeeze().T\n",
    "        self.temp_output = self.actn_fn(z)\n",
    "        return self.temp_output\n",
    "    \n",
    "    def backward(self, inp:np.array, out:np.array, lr:float=0.01, prev_back:np.array=None):\n",
    "        if self.actn_fn == self.softmax:\n",
    "            dw = self.temp_output - out\n",
    "            dwdx = dw @ inp\n",
    "            self.weights = self.weights - lr * dwdx\n",
    "        elif self.actn_fn == self.sigmoid:\n",
    "            dsig = self.temp_output * (1-self.temp_output)\n",
    "            dsigdw = dsig * inp\n",
    "            self.weights -= (lr * dsigdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tangrad:    \n",
    "    def __init__(self, layer:list[Layer]=[], inp_features:int=None):\n",
    "        self.layer = layer\n",
    "        self.inp_features = inp_features\n",
    "    \n",
    "    def add_layer(self, layer:Layer):\n",
    "        self.layer.append(layer)\n",
    "    \n",
    "    def compile(self):\n",
    "        compiled = 0\n",
    "        for i in range(len(self.layer)):\n",
    "            if i == 0:\n",
    "                compiled = self.layer[i].compile(self.inp_features)\n",
    "                print(self.layer[i])\n",
    "            else:\n",
    "                compiled = self.layer[i].compile(compiled)\n",
    "                print(self.layer[i])\n",
    "        \n",
    "    def fit(self, inp:np.array, out:np.array, lr:float=0.01):\n",
    "        for i in self.layer:\n",
    "            inp = i.forward(inp)\n",
    "        # for i in range(len(self.layer),-1,-1):\n",
    "        #     self.layer[i].backward(inp, out, lr)\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ann = Tangrad(inp_features=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = Layer(4, \"sigmoid\",\"layer 0\")\n",
    "layer_1 = Layer(20, \"sigmoid\",\"layer 1\")\n",
    "layer_2 = Layer(10, \"sigmoid\",\"layer 2\")\n",
    "layer_3 = Layer(1, \"sigmoid\",\"layer 3\")\n",
    "Ann.add_layer(layer_0)\n",
    "Ann.add_layer(layer_1)\n",
    "Ann.add_layer(layer_2)\n",
    "Ann.add_layer(layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer : layer 0, activation function : <bound method Layer.sigmoid of <__main__.Layer object at 0x7374073f4ad0>>, No. of neurons : 4\n",
      "Layer : layer 1, activation function : <bound method Layer.sigmoid of <__main__.Layer object at 0x737407432e90>>, No. of neurons : 20\n",
      "Layer : layer 2, activation function : <bound method Layer.sigmoid of <__main__.Layer object at 0x737407432fd0>>, No. of neurons : 10\n",
      "Layer : layer 3, activation function : <bound method Layer.sigmoid of <__main__.Layer object at 0x73740742b490>>, No. of neurons : 1\n"
     ]
    }
   ],
   "source": [
    "Ann.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris  = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data[:, :]\n",
    "y = iris.target_names[iris.target] == \"virginica\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "traindata = scaler.fit_transform(x_train)\n",
    "testdata = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ann.fit(traindata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
